transformer_block_type = 'SASP'
wandb_run_name = 'SASPV-dr_0.2'
out_dir = 'analysis/size_25M/SASPV-dr_0.2'
wandb_project = 'SASP-25M-analysis'
dataset = 'shakespeare_char'
eval_interval = 200
eval_iters = 100
log_interval = 10
always_save_checkpoint = False
wandb_log = True
gradient_accumulation_steps = 1
batch_size = 128
block_size = 256
n_layer = 8
n_head = 8
learning_rate = 0.2e-3
max_iters = 45000
lr_decay_iters = 45000
min_lr = 0.2e-4
beta2 = 0.99
warmup_iters = 2000
dropout = 0.2
use_v = True
n_embd = 520