## Architecture Playground

I forked Andrej Karpathy's [nanoGPT](https://github.com/karpathy/nanoGPT) to create an easy-to-use playground for experimenting with transformer architectures.  nanoGPT is a simple and fast repository for training/finetuning medium-sized GPTs.  The local instructions for settup for this repo are found [here](docs/nanoGPT-README.md). 

* Signal Propgation Analysis
* [Flexible Transfomer Architecture](docs/simplified-transformers_README.md)
* Flexible Transformer w/ ALiBi
* Diffusion Language Model 

